#!/usr/bin/env python3
"""å®éªŒç®¡ç† CLI â€” åˆ—è¡¨ / ç­›é€‰ / æ¸…ç† / å½’æ¡£ / è¯¦æƒ… / æœ€ä½³.

Usage:
    # åˆ—å‡ºæ‰€æœ‰å®éªŒ
    python scripts/manage_experiments.py list

    # åªçœ‹æˆåŠŸçš„å®éªŒï¼ŒæŒ‰ accuracy é™åº
    python scripts/manage_experiments.py list --status completed --sort accuracy --desc

    # æŒ‰æ ‡ç­¾ç­›é€‰
    python scripts/manage_experiments.py list --tags baseline v1

    # æœç´¢åç§°åŒ…å« "flow" çš„å®éªŒ
    python scripts/manage_experiments.py list --search flow

    # æŸ¥çœ‹å•ä¸ªå®éªŒè¯¦æƒ…
    python scripts/manage_experiments.py show <experiment_id>

    # æŸ¥çœ‹æŒ‡æ ‡æœ€ä¼˜çš„å®éªŒ
    python scripts/manage_experiments.py best --metric f1_macro

    # æ¸…ç†æ‰€æœ‰å¤±è´¥çš„å®éªŒï¼ˆåˆ é™¤ç›®å½•+æ³¨å†Œè¡¨ï¼‰
    python scripts/manage_experiments.py cleanup

    # å½’æ¡£æŒ‡å®šæ—¥æœŸä¹‹å‰çš„å®éªŒ
    python scripts/manage_experiments.py archive --before 2026-02-01

    # å½’æ¡£æŒ‡å®šå®éªŒ
    python scripts/manage_experiments.py archive --ids exp_id_1 exp_id_2

    # åˆ é™¤æŒ‡å®šå®éªŒ
    python scripts/manage_experiments.py delete <experiment_id>

    # å¯¼å‡ºæ³¨å†Œè¡¨ä¸º CSV
    python scripts/manage_experiments.py export --output reports/experiments.csv
"""

import argparse
import csv
import json
import sys
from pathlib import Path
from datetime import datetime

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.utils.logging import setup_logging
from src.experiment.tracker import (
    list_experiments,
    filter_experiments,
    delete_experiment,
    cleanup_failed,
    archive_experiments,
    get_experiment_summary,
    get_best_experiment,
    EXPERIMENTS_DIR,
)


# â”€â”€â”€ æ ¼å¼åŒ–è¾…åŠ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _status_icon(status: str) -> str:
    return {"completed": "âœ…", "failed": "âŒ", "running": "ğŸ”„"}.get(status, "â“")


def _duration_str(seconds) -> str:
    if seconds is None:
        return "-"
    if seconds < 60:
        return f"{seconds:.0f}s"
    return f"{seconds / 60:.1f}min"


def _metric_str(val) -> str:
    if val is None:
        return "-"
    if isinstance(val, float):
        return f"{val:.4f}"
    return str(val)


def _print_table(rows: list[dict], columns: list[tuple[str, str, int]]):
    """ç®€æ˜“è¡¨æ ¼æ‰“å°.

    columns: [(key, header, width), ...]
    """
    # è¡¨å¤´
    header = " | ".join(h.ljust(w) for _, h, w in columns)
    sep = "-+-".join("-" * w for _, _, w in columns)
    print(header)
    print(sep)
    for row in rows:
        line = " | ".join(str(row.get(k, "-"))[:w].ljust(w) for k, _, w in columns)
        print(line)


def _format_experiment_row(entry: dict) -> dict:
    """å°†æ³¨å†Œè¡¨æ¡ç›®æ ¼å¼åŒ–ä¸ºå¯æ˜¾ç¤ºçš„è¡Œ."""
    metrics = entry.get("aggregate_metrics", {})
    created = entry.get("created_at", "")
    if created:
        try:
            dt = datetime.fromisoformat(created)
            created = dt.strftime("%m-%d %H:%M")
        except Exception:
            created = created[:16]

    return {
        "status": _status_icon(entry.get("status", "")),
        "id": entry.get("experiment_id", "")[-20:],  # æˆªçŸ­æ˜¾ç¤º
        "full_id": entry.get("experiment_id", ""),
        "name": entry.get("name", ""),
        "tags": ",".join(entry.get("tags", [])),
        "created": created,
        "duration": _duration_str(entry.get("duration_seconds")),
        "acc": _metric_str(metrics.get("accuracy")),
        "f1": _metric_str(metrics.get("f1_macro")),
        "kappa": _metric_str(metrics.get("cohen_kappa")),
        "git": entry.get("git_commit", "?"),
        "error": (entry.get("error") or "")[:40],
    }


# â”€â”€â”€ å­å‘½ä»¤å®ç° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def cmd_list(args):
    """åˆ—å‡ºå®éªŒ."""
    results = filter_experiments(
        status=args.status,
        tags=args.tags,
        name_contains=args.search,
        sort_by=args.sort,
        ascending=not args.desc,
        top_n=args.top,
    )

    if not results:
        print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å®éªŒ")
        return

    rows = [_format_experiment_row(e) for e in results]

    print(f"\nğŸ“‹ å…± {len(results)} ä¸ªå®éªŒ\n")

    columns = [
        ("status", "St", 2),
        ("name", "Name", 18),
        ("created", "Created", 11),
        ("duration", "Time", 7),
        ("acc", "Acc", 6),
        ("f1", "F1", 6),
        ("kappa", "Kappa", 6),
        ("git", "Git", 7),
        ("tags", "Tags", 15),
        ("id", "ID (last 20)", 20),
    ]
    _print_table(rows, columns)

    # å¦‚æœæœ‰å¤±è´¥çš„ï¼Œé¢å¤–æç¤º
    failed_count = sum(1 for e in results if e.get("status") == "failed")
    if failed_count:
        print(f"\nâš ï¸  æœ‰ {failed_count} ä¸ªå¤±è´¥å®éªŒï¼Œå¯ç”¨ `cleanup` æ¸…ç†")


def cmd_show(args):
    """æŸ¥çœ‹å®éªŒè¯¦æƒ…."""
    # æ”¯æŒéƒ¨åˆ† ID åŒ¹é…
    experiment_id = _resolve_experiment_id(args.experiment_id)
    if not experiment_id:
        return

    summary = get_experiment_summary(experiment_id)
    if not summary:
        print(f"âŒ æ‰¾ä¸åˆ°å®éªŒ: {experiment_id}")
        return

    print(f"\n{'='*60}")
    print(f"  å®éªŒè¯¦æƒ…: {experiment_id}")
    print(f"{'='*60}")
    print(f"  çŠ¶æ€:     {_status_icon(summary.get('status', ''))} {summary.get('status', '')}")
    print(f"  åç§°:     {summary.get('name', '')}")
    print(f"  æè¿°:     {summary.get('description', '')}")
    print(f"  æ ‡ç­¾:     {summary.get('tags', [])}")
    print(f"  åˆ›å»ºæ—¶é—´: {summary.get('created_at', '')}")
    print(f"  è€—æ—¶:     {_duration_str(summary.get('duration_seconds'))}")
    print(f"  ç§å­:     {summary.get('seed')}")

    git = summary.get("git", {})
    print(f"  Git:      {git.get('branch', '?')}@{git.get('commit', '?')} {'(dirty)' if git.get('dirty') else '(clean)'}")

    metrics = summary.get("aggregate_metrics", {})
    if metrics:
        print(f"\n  ğŸ“Š æ±‡æ€»æŒ‡æ ‡:")
        for k, v in metrics.items():
            print(f"     {k:20s}: {_metric_str(v)}")

    if summary.get("error"):
        print(f"\n  âŒ é”™è¯¯: {summary['error']}")

    # æ£€æŸ¥äº§ç‰©
    exp_dir = EXPERIMENTS_DIR / experiment_id
    if exp_dir.exists():
        files = sorted(exp_dir.iterdir())
        print(f"\n  ğŸ“ äº§ç‰© ({len(files)} æ–‡ä»¶):")
        for f in files:
            size = f.stat().st_size
            size_str = f"{size / 1024:.1f}KB" if size > 1024 else f"{size}B"
            print(f"     {f.name:30s}  {size_str}")

    print(f"{'='*60}\n")


def cmd_best(args):
    """æŸ¥çœ‹æœ€ä¼˜å®éªŒ."""
    best = get_best_experiment(
        metric=args.metric,
        higher_is_better=not args.lower,
    )
    if not best:
        print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°æˆåŠŸå®Œæˆçš„å®éªŒ")
        return

    metrics = best.get("aggregate_metrics", {})
    print(f"\nğŸ† æœ€ä¼˜å®éªŒ (æŒ‰ {args.metric}):")
    print(f"   ID:     {best['experiment_id']}")
    print(f"   Name:   {best.get('name', '')}")
    print(f"   {args.metric}: {_metric_str(metrics.get(args.metric))}")
    print(f"   æ‰€æœ‰æŒ‡æ ‡: {json.dumps(metrics, indent=2)}")
    print()


def cmd_cleanup(args):
    """æ¸…ç†å¤±è´¥çš„å®éªŒ."""
    if not args.yes:
        failed = filter_experiments(status="failed")
        if not failed:
            print("âœ… æ²¡æœ‰å¤±è´¥çš„å®éªŒéœ€è¦æ¸…ç†")
            return
        print(f"âš ï¸  å°†æ¸…ç†ä»¥ä¸‹ {len(failed)} ä¸ªå¤±è´¥å®éªŒ:")
        for e in failed:
            print(f"   - {e['experiment_id']}")
        confirm = input("\nç¡®è®¤åˆ é™¤? (y/N): ").strip().lower()
        if confirm != "y":
            print("å·²å–æ¶ˆ")
            return

    deleted = cleanup_failed(delete_files=True)
    if deleted:
        print(f"\nğŸ§¹ å·²æ¸…ç† {len(deleted)} ä¸ªå¤±è´¥å®éªŒ:")
        for eid in deleted:
            print(f"   âœ… {eid}")
    else:
        print("âœ… æ²¡æœ‰å¤±è´¥çš„å®éªŒéœ€è¦æ¸…ç†")


def cmd_archive(args):
    """å½’æ¡£å®éªŒ."""
    archived = archive_experiments(
        experiment_ids=args.ids,
        before_date=args.before,
        status=args.status,
    )
    if archived:
        print(f"\nğŸ“¦ å·²å½’æ¡£ {len(archived)} ä¸ªå®éªŒ:")
        for eid in archived:
            print(f"   ğŸ“¦ {eid}")
        print(f"\nå½’æ¡£ç›®å½•: experiments_archive/")
    else:
        print("ğŸ“­ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å®éªŒéœ€è¦å½’æ¡£")


def cmd_delete(args):
    """åˆ é™¤æŒ‡å®šå®éªŒ."""
    experiment_id = _resolve_experiment_id(args.experiment_id)
    if not experiment_id:
        return

    if not args.yes:
        confirm = input(f"âš ï¸  ç¡®è®¤åˆ é™¤å®éªŒ '{experiment_id}'? (y/N): ").strip().lower()
        if confirm != "y":
            print("å·²å–æ¶ˆ")
            return

    if delete_experiment(experiment_id, delete_files=True):
        print(f"âœ… å·²åˆ é™¤å®éªŒ: {experiment_id}")
    else:
        print(f"âŒ åˆ é™¤å¤±è´¥: {experiment_id}")


def cmd_export(args):
    """å¯¼å‡ºæ³¨å†Œè¡¨ä¸º CSV."""
    registry = list_experiments()
    if not registry:
        print("ğŸ“­ æ³¨å†Œè¡¨ä¸ºç©º")
        return

    output = Path(args.output)
    output.parent.mkdir(parents=True, exist_ok=True)

    # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„æŒ‡æ ‡å
    all_metric_keys = set()
    for e in registry:
        all_metric_keys.update(e.get("aggregate_metrics", {}).keys())
    all_metric_keys = sorted(all_metric_keys)

    fieldnames = [
        "experiment_id", "name", "status", "created_at",
        "duration_seconds", "git_commit", "git_branch", "seed", "tags",
    ] + all_metric_keys + ["error"]

    with open(output, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction="ignore")
        writer.writeheader()
        for entry in registry:
            row = {**entry}
            row["tags"] = ",".join(entry.get("tags", []))
            # å±•å¹³ metrics
            for mk in all_metric_keys:
                row[mk] = entry.get("aggregate_metrics", {}).get(mk)
            writer.writerow(row)

    print(f"âœ… å·²å¯¼å‡º {len(registry)} æ¡è®°å½•åˆ° {output}")


# â”€â”€â”€ è¾…åŠ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _resolve_experiment_id(partial_id: str) -> str | None:
    """æ”¯æŒéƒ¨åˆ† ID åŒ¹é…ï¼ˆä»æ³¨å†Œè¡¨ä¸­æŸ¥æ‰¾å”¯ä¸€åŒ¹é…ï¼‰."""
    registry = list_experiments()
    matches = [e for e in registry if partial_id in e["experiment_id"]]

    if len(matches) == 0:
        print(f"âŒ æ‰¾ä¸åˆ°åŒ¹é… '{partial_id}' çš„å®éªŒ")
        return None
    elif len(matches) == 1:
        return matches[0]["experiment_id"]
    else:
        print(f"âš ï¸  '{partial_id}' åŒ¹é…äº†å¤šä¸ªå®éªŒï¼Œè¯·æ›´ç²¾ç¡®:")
        for m in matches:
            print(f"   - {m['experiment_id']}")
        return None


# â”€â”€â”€ CLI å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="FcstLabPro å®éªŒç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    subparsers = parser.add_subparsers(dest="command", help="å­å‘½ä»¤")

    # list
    p_list = subparsers.add_parser("list", aliases=["ls"], help="åˆ—å‡ºå®éªŒ")
    p_list.add_argument("--status", choices=["completed", "failed", "running"], help="æŒ‰çŠ¶æ€ç­›é€‰")
    p_list.add_argument("--tags", nargs="+", help="æŒ‰æ ‡ç­¾ç­›é€‰ï¼ˆå¿…é¡»åŒ…å«æ‰€æœ‰æŒ‡å®šæ ‡ç­¾ï¼‰")
    p_list.add_argument("--search", help="æœç´¢åç§°/ID")
    p_list.add_argument("--sort", help="æ’åºå­—æ®µ (created_at/duration_seconds/accuracy/f1_macro/...)")
    p_list.add_argument("--desc", action="store_true", help="é™åºæ’åˆ—")
    p_list.add_argument("--top", type=int, help="åªæ˜¾ç¤ºå‰ N ä¸ª")

    # show
    p_show = subparsers.add_parser("show", help="æŸ¥çœ‹å®éªŒè¯¦æƒ…")
    p_show.add_argument("experiment_id", help="å®éªŒ IDï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰")

    # best
    p_best = subparsers.add_parser("best", help="æŸ¥çœ‹æœ€ä¼˜å®éªŒ")
    p_best.add_argument("--metric", default="accuracy", help="è¯„æ¯”æŒ‡æ ‡ (é»˜è®¤: accuracy)")
    p_best.add_argument("--lower", action="store_true", help="è¶Šä½è¶Šå¥½ï¼ˆå¦‚ lossï¼‰")

    # cleanup
    p_cleanup = subparsers.add_parser("cleanup", help="æ¸…ç†æ‰€æœ‰å¤±è´¥çš„å®éªŒ")
    p_cleanup.add_argument("-y", "--yes", action="store_true", help="è·³è¿‡ç¡®è®¤")

    # archive
    p_archive = subparsers.add_parser("archive", help="å½’æ¡£å®éªŒ")
    p_archive.add_argument("--ids", nargs="+", help="æŒ‡å®šå®éªŒ ID")
    p_archive.add_argument("--before", help="å½’æ¡£æ­¤æ—¥æœŸä¹‹å‰çš„å®éªŒ (ISO æ ¼å¼)")
    p_archive.add_argument("--status", help="å½’æ¡£æŒ‡å®šçŠ¶æ€çš„å®éªŒ")

    # delete
    p_delete = subparsers.add_parser("delete", aliases=["rm"], help="åˆ é™¤å®éªŒ")
    p_delete.add_argument("experiment_id", help="å®éªŒ IDï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰")
    p_delete.add_argument("-y", "--yes", action="store_true", help="è·³è¿‡ç¡®è®¤")

    # export
    p_export = subparsers.add_parser("export", help="å¯¼å‡ºæ³¨å†Œè¡¨ä¸º CSV")
    p_export.add_argument("--output", default="reports/experiments_registry.csv", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    setup_logging(level="INFO")

    if args.command in ("list", "ls"):
        cmd_list(args)
    elif args.command == "show":
        cmd_show(args)
    elif args.command == "best":
        cmd_best(args)
    elif args.command == "cleanup":
        cmd_cleanup(args)
    elif args.command == "archive":
        cmd_archive(args)
    elif args.command in ("delete", "rm"):
        cmd_delete(args)
    elif args.command == "export":
        cmd_export(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
