"""å®éªŒå¯¹æ¯”åˆ†ææ¨¡å— â€” ç”Ÿæˆè¯¦ç»†çš„ Markdown å¯¹æ¯”æŠ¥å‘Š."""

import json
import logging
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
from tabulate import tabulate

logger = logging.getLogger(__name__)


def load_experiment_metrics(exp_dir: str | Path) -> dict:
    """åŠ è½½å•ä¸ªå®éªŒçš„æŒ‡æ ‡."""
    exp_dir = Path(exp_dir)
    metrics_path = exp_dir / "metrics.json"
    if not metrics_path.exists():
        raise FileNotFoundError(f"æŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {metrics_path}")
    with open(metrics_path) as f:
        return json.load(f)


def load_experiment_meta(exp_dir: str | Path) -> dict:
    """åŠ è½½å•ä¸ªå®éªŒçš„å…ƒä¿¡æ¯."""
    exp_dir = Path(exp_dir)
    meta_path = exp_dir / "meta.json"
    if not meta_path.exists():
        return {}
    with open(meta_path) as f:
        return json.load(f)


def load_experiment_config(exp_dir: str | Path) -> dict:
    """åŠ è½½å•ä¸ªå®éªŒçš„é…ç½®."""
    import yaml
    exp_dir = Path(exp_dir)
    config_path = exp_dir / "config.yaml"
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    with open(config_path) as f:
        return yaml.safe_load(f)


def load_fold_metrics(exp_dir: str | Path) -> pd.DataFrame | None:
    """åŠ è½½ fold æŒ‡æ ‡."""
    exp_dir = Path(exp_dir)
    fold_path = exp_dir / "fold_metrics.csv"
    if not fold_path.exists():
        return None
    return pd.read_csv(fold_path)


def load_feature_importance(exp_dir: str | Path) -> pd.DataFrame | None:
    """åŠ è½½ç‰¹å¾é‡è¦æ€§."""
    exp_dir = Path(exp_dir)
    fi_path = exp_dir / "feature_importance.csv"
    if not fi_path.exists():
        return None
    return pd.read_csv(fi_path)


def _fmt(val, fmt=".4f") -> str:
    """æ ¼å¼åŒ–æ•°å€¼."""
    if val is None or (isinstance(val, float) and np.isnan(val)):
        return "-"
    if isinstance(val, float):
        return f"{val:{fmt}}"
    return str(val)


def _delta_str(val: float, higher_is_better: bool = True) -> str:
    """æ ¼å¼åŒ–å·®å€¼ï¼Œå¸¦æ¶¨è·Œç®­å¤´."""
    if val > 0:
        arrow = "ğŸ“ˆ" if higher_is_better else "ğŸ“‰"
        return f"{arrow} +{val:.4f}"
    elif val < 0:
        arrow = "ğŸ“‰" if higher_is_better else "ğŸ“ˆ"
        return f"{arrow} {val:.4f}"
    return "â†’ 0.0000"


# æŒ‡æ ‡æ˜¯å¦è¶Šé«˜è¶Šå¥½
_HIGHER_IS_BETTER = {
    "accuracy": True,
    "f1_macro": True,
    "precision_macro": True,
    "recall_macro": True,
    "cohen_kappa": True,
}


def compare_experiments(
    experiment_dirs: list[str | Path],
    output_path: str | Path | None = None,
) -> str:
    """å¯¹æ¯”å¤šä¸ªå®éªŒï¼Œç”Ÿæˆè¯¦ç»† Markdown å¯¹æ¯”æŠ¥å‘Š.

    Parameters
    ----------
    experiment_dirs : list[str | Path]
        å®éªŒç›®å½•åˆ—è¡¨
    output_path : str | Path | None
        æŠ¥å‘Šè¾“å‡ºè·¯å¾„

    Returns
    -------
    str
        Markdown æ ¼å¼çš„å¯¹æ¯”æŠ¥å‘Š
    """
    # â”€â”€ æ”¶é›†æ‰€æœ‰å®éªŒæ•°æ® â”€â”€
    experiments = []
    for exp_dir in experiment_dirs:
        exp_dir = Path(exp_dir)
        exp_id = exp_dir.name
        try:
            metrics = load_experiment_metrics(exp_dir)
            config = load_experiment_config(exp_dir)
            meta = load_experiment_meta(exp_dir)
            fold_df = load_fold_metrics(exp_dir)
            fi_df = load_feature_importance(exp_dir)
        except FileNotFoundError as e:
            logger.warning(f"è·³è¿‡å®éªŒ {exp_id}: {e}")
            continue

        experiments.append({
            "id": exp_id,
            "short_id": meta.get("name", exp_id[:25]),
            "metrics": metrics,
            "config": config,
            "meta": meta,
            "fold_df": fold_df,
            "fi_df": fi_df,
            "dir": exp_dir,
        })

    if not experiments:
        return "æ²¡æœ‰å¯å¯¹æ¯”çš„å®éªŒæ•°æ®"

    lines = []

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # æ ‡é¢˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("# ğŸ“Š FcstLabPro å®éªŒå¯¹æ¯”æŠ¥å‘Š")
    lines.append("")
    lines.append(f"> **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  ")
    lines.append(f"> **å¯¹æ¯”å®éªŒæ•°**: {len(experiments)}  ")
    lines.append(f"> **å¹³å°**: FcstLabPro")
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. å®éªŒæ¦‚è§ˆ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("---")
    lines.append("## 1. å®éªŒæ¦‚è§ˆ")
    lines.append("")

    overview_rows = []
    for exp in experiments:
        meta = exp["meta"]
        cfg = exp["config"]
        feat_sets = cfg.get("features", {}).get("sets", [])
        overview_rows.append({
            "å®éªŒå": exp["short_id"],
            "å¤§ç±»": meta.get("category", "default"),
            "æ ‡ç­¾": ", ".join(meta.get("tags", [])),
            "æè¿°": meta.get("description", "")[:50],
            "ç‰¹å¾é›†æ•°": len(feat_sets),
            "åˆ›å»ºæ—¶é—´": meta.get("created_at", "")[:19],
            "è€—æ—¶": f"{meta.get('duration_seconds', 0):.0f}s",
            "Git": meta.get("git", {}).get("commit", "?"),
            "çŠ¶æ€": meta.get("status", "?"),
        })

    lines.append(tabulate(overview_rows, headers="keys", tablefmt="pipe"))
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("---")
    lines.append("## 2. æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”")
    lines.append("")

    # æ„å»ºæŒ‡æ ‡è¡¨
    all_metric_keys = sorted(set().union(*(exp["metrics"].keys() for exp in experiments)))
    metric_rows = []
    for exp in experiments:
        row = {"å®éªŒ": exp["short_id"]}
        for k in all_metric_keys:
            row[k] = _fmt(exp["metrics"].get(k))
        metric_rows.append(row)

    lines.append(tabulate(metric_rows, headers="keys", tablefmt="pipe"))
    lines.append("")

    # å¦‚æœæœ‰ 2 ä¸ªå®éªŒï¼Œæ˜¾ç¤ºå·®å€¼å¯¹æ¯”
    if len(experiments) == 2:
        lines.append("### æŒ‡æ ‡å·®å¼‚ (å®éªŒ2 âˆ’ å®éªŒ1)")
        lines.append("")
        exp1, exp2 = experiments[0], experiments[1]
        for k in all_metric_keys:
            v1 = exp1["metrics"].get(k, 0) or 0
            v2 = exp2["metrics"].get(k, 0) or 0
            delta = v2 - v1
            hib = _HIGHER_IS_BETTER.get(k, True)
            lines.append(f"- **{k}**: {_delta_str(delta, hib)}")
        lines.append("")

    # æœ€ä½³æŒ‡æ ‡é«˜äº®
    if len(experiments) > 1:
        lines.append("### ğŸ† å„æŒ‡æ ‡æœ€ä½³")
        lines.append("")
        for k in all_metric_keys:
            hib = _HIGHER_IS_BETTER.get(k, True)
            best_exp = max(experiments, key=lambda e: e["metrics"].get(k, float('-inf')) if hib
                          else -e["metrics"].get(k, float('inf')))
            best_val = best_exp["metrics"].get(k, 0)
            lines.append(f"- **{k}**: {best_exp['short_id']} ({_fmt(best_val)})")
        lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. é…ç½®å·®å¼‚å¯¹æ¯”
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("---")
    lines.append("## 3. é…ç½®å·®å¼‚å¯¹æ¯”")
    lines.append("")

    # å…³é”®é…ç½®é¡¹å¯¹æ¯”
    config_compare_keys = [
        ("features.sets", lambda c: ", ".join(c.get("features", {}).get("sets", []))),
        ("features.sets (æ•°é‡)", lambda c: str(len(c.get("features", {}).get("sets", [])))),
        ("label.strategy", lambda c: str(c.get("label", {}).get("strategy", "N/A"))),
        ("label.T", lambda c: str(c.get("label", {}).get("T", "N/A"))),
        ("label.X", lambda c: str(c.get("label", {}).get("X", "N/A"))),
        ("model.type", lambda c: str(c.get("model", {}).get("type", "N/A"))),
        ("model.n_estimators", lambda c: str(c.get("model", {}).get("params", {}).get("n_estimators", "N/A"))),
        ("model.max_depth", lambda c: str(c.get("model", {}).get("params", {}).get("max_depth", "N/A"))),
        ("model.learning_rate", lambda c: str(c.get("model", {}).get("params", {}).get("learning_rate", "N/A"))),
        ("model.num_leaves", lambda c: str(c.get("model", {}).get("params", {}).get("num_leaves", "N/A"))),
        ("model.subsample", lambda c: str(c.get("model", {}).get("params", {}).get("subsample", "N/A"))),
        ("eval.init_train", lambda c: str(c.get("evaluation", {}).get("init_train", "N/A"))),
        ("eval.oos_window", lambda c: str(c.get("evaluation", {}).get("oos_window", "N/A"))),
        ("eval.step", lambda c: str(c.get("evaluation", {}).get("step", "N/A"))),
        ("seed", lambda c: str(c.get("seed", "N/A"))),
    ]

    cfg_rows = []
    for key_name, extractor in config_compare_keys:
        row = {"é…ç½®é¡¹": key_name}
        values = []
        for exp in experiments:
            val = extractor(exp["config"])
            row[exp["short_id"]] = val
            values.append(val)
        # æ ‡è®°å·®å¼‚
        row["å·®å¼‚"] = "âœ… ç›¸åŒ" if len(set(values)) == 1 else "âš¡ ä¸åŒ"
        cfg_rows.append(row)

    lines.append(tabulate(cfg_rows, headers="keys", tablefmt="pipe"))
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. Walk-Forward Fold æŒ‡æ ‡å¯¹æ¯”
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    fold_dfs_available = [exp for exp in experiments if exp["fold_df"] is not None]
    if fold_dfs_available:
        lines.append("---")
        lines.append("## 4. Walk-Forward Fold æŒ‡æ ‡å¯¹æ¯”")
        lines.append("")

        # æ¯ä¸ªå®éªŒçš„ fold ç»Ÿè®¡
        for exp in fold_dfs_available:
            fold_df = exp["fold_df"]
            lines.append(f"### {exp['short_id']}")
            lines.append(f"- Folds æ•°é‡: {len(fold_df)}")

            for metric in ["accuracy", "f1_macro", "cohen_kappa"]:
                if metric in fold_df.columns:
                    vals = fold_df[metric]
                    lines.append(
                        f"- **{metric}**: mean={vals.mean():.4f}, "
                        f"std={vals.std():.4f}, "
                        f"min={vals.min():.4f}, max={vals.max():.4f}"
                    )
            lines.append("")

        # è·¨å®éªŒ fold æ±‡æ€»å¯¹æ¯”è¡¨
        if len(fold_dfs_available) > 1:
            lines.append("### Fold æŒ‡æ ‡ç»Ÿè®¡æ±‡æ€»å¯¹æ¯”")
            lines.append("")

            summary_rows = []
            for exp in fold_dfs_available:
                fold_df = exp["fold_df"]
                row = {"å®éªŒ": exp["short_id"], "Folds": len(fold_df)}
                for metric in ["accuracy", "f1_macro", "cohen_kappa"]:
                    if metric in fold_df.columns:
                        vals = fold_df[metric]
                        row[f"{metric} (meanÂ±std)"] = f"{vals.mean():.4f}Â±{vals.std():.4f}"
                summary_rows.append(row)

            lines.append(tabulate(summary_rows, headers="keys", tablefmt="pipe"))
            lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. ç‰¹å¾é‡è¦æ€§å¯¹æ¯”
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    fi_available = [exp for exp in experiments if exp["fi_df"] is not None]
    if fi_available:
        lines.append("---")
        lines.append("## 5. ç‰¹å¾é‡è¦æ€§å¯¹æ¯”")
        lines.append("")

        # Top 20 ç‰¹å¾å¯¹æ¯”
        TOP_N = 20
        lines.append(f"### Top {TOP_N} ç‰¹å¾")
        lines.append("")

        for exp in fi_available:
            fi_df = exp["fi_df"].head(TOP_N)
            lines.append(f"#### {exp['short_id']} (å…± {len(exp['fi_df'])} ä¸ªç‰¹å¾)")
            lines.append("")
            fi_rows = []
            total_imp = exp["fi_df"]["importance"].sum()
            for idx, row in fi_df.iterrows():
                pct = row["importance"] / total_imp * 100 if total_imp > 0 else 0
                fi_rows.append({
                    "æ’å": idx + 1,
                    "ç‰¹å¾": row["feature"],
                    "é‡è¦æ€§": int(row["importance"]),
                    "å æ¯”": f"{pct:.1f}%",
                })
            lines.append(tabulate(fi_rows, headers="keys", tablefmt="pipe"))
            lines.append("")

        # å¦‚æœæœ‰ 2 ä¸ªå®éªŒï¼Œå¯¹æ¯” Top ç‰¹å¾çš„äº¤é›†å’Œå·®é›†
        if len(fi_available) == 2:
            lines.append("### ç‰¹å¾é‡è¦æ€§äº¤é›†ä¸å·®å¼‚åˆ†æ")
            lines.append("")

            top1 = set(fi_available[0]["fi_df"].head(TOP_N)["feature"].tolist())
            top2 = set(fi_available[1]["fi_df"].head(TOP_N)["feature"].tolist())

            common = top1 & top2
            only_1 = top1 - top2
            only_2 = top2 - top1

            lines.append(f"- **å…±åŒ Top{TOP_N} ç‰¹å¾** ({len(common)} ä¸ª): {', '.join(sorted(common)) if common else 'æ— '}")
            lines.append(f"- **ä»… {fi_available[0]['short_id']} Top{TOP_N}** ({len(only_1)} ä¸ª): {', '.join(sorted(only_1)) if only_1 else 'æ— '}")
            lines.append(f"- **ä»… {fi_available[1]['short_id']} Top{TOP_N}** ({len(only_2)} ä¸ª): {', '.join(sorted(only_2)) if only_2 else 'æ— '}")
            union_size = len(top1 | top2)
            lines.append(f"- **Jaccard ç›¸ä¼¼åº¦**: {len(common) / union_size:.2%}" if union_size > 0 else "- **Jaccard ç›¸ä¼¼åº¦**: N/A")
            lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. æ•°æ®ä¸ç‰¹å¾ç»´åº¦
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("---")
    lines.append("## 6. æ•°æ®ä¸ç‰¹å¾ç»´åº¦")
    lines.append("")

    dim_rows = []
    for exp in experiments:
        cfg = exp["config"]
        feat_sets = cfg.get("features", {}).get("sets", [])
        n_features = len(exp["fi_df"]) if exp["fi_df"] is not None else "N/A"
        dim_rows.append({
            "å®éªŒ": exp["short_id"],
            "æ•°æ®åŒºé—´": f"{cfg.get('data', {}).get('start', '?')} ~ {cfg.get('data', {}).get('end', '?')}",
            "ç‰¹å¾é›†": ", ".join(feat_sets),
            "ç‰¹å¾æ•°": n_features,
            "æ¨¡å‹ç±»å‹": cfg.get("model", {}).get("type", "N/A"),
        })

    lines.append(tabulate(dim_rows, headers="keys", tablefmt="pipe"))
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ç»“è®ºä¸å»ºè®®
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("---")
    lines.append("## 7. ç»“è®ºä¸å»ºè®®")
    lines.append("")

    if len(experiments) >= 2:
        # è‡ªåŠ¨ç”Ÿæˆå…³é”®å‘ç°
        lines.append("### å…³é”®å‘ç°")
        lines.append("")

        # æ‰¾æœ€ä½³å®éªŒ
        best_acc_exp = max(experiments, key=lambda e: e["metrics"].get("accuracy", 0))
        best_f1_exp = max(experiments, key=lambda e: e["metrics"].get("f1_macro", 0))
        best_kappa_exp = max(experiments, key=lambda e: e["metrics"].get("cohen_kappa", float("-inf")))

        lines.append(f"1. **Accuracy æœ€ä½³**: {best_acc_exp['short_id']} ({_fmt(best_acc_exp['metrics'].get('accuracy'))})")
        lines.append(f"2. **F1-Macro æœ€ä½³**: {best_f1_exp['short_id']} ({_fmt(best_f1_exp['metrics'].get('f1_macro'))})")
        lines.append(f"3. **Cohen's Kappa æœ€ä½³**: {best_kappa_exp['short_id']} ({_fmt(best_kappa_exp['metrics'].get('cohen_kappa'))})")
        lines.append("")

        # é…ç½®å·®å¼‚åˆ†æ
        feat_sets_list = [set(e["config"].get("features", {}).get("sets", [])) for e in experiments]
        if len(set(frozenset(s) for s in feat_sets_list)) > 1:
            lines.append("4. **ç‰¹å¾é›†å·®å¼‚**: å„å®éªŒä½¿ç”¨äº†ä¸åŒçš„ç‰¹å¾é›†ç»„åˆï¼Œè¿™å¯èƒ½æ˜¯æ€§èƒ½å·®å¼‚çš„ä¸»è¦å› ç´ ")
        else:
            lines.append("4. **ç‰¹å¾é›†ç›¸åŒ**: å„å®éªŒä½¿ç”¨äº†ç›¸åŒçš„ç‰¹å¾é›†ï¼Œæ€§èƒ½å·®å¼‚å¯èƒ½æ¥è‡ªå…¶ä»–è¶…å‚æ•°")

        n_estimators_list = [e["config"].get("model", {}).get("params", {}).get("n_estimators") for e in experiments]
        if len(set(n_estimators_list)) > 1:
            lines.append(f"5. **æ¨¡å‹å¤æ‚åº¦ä¸åŒ**: n_estimators åˆ†åˆ«ä¸º {n_estimators_list}")
        lines.append("")

        lines.append("### å»ºè®®åç»­å®éªŒ")
        lines.append("")
        lines.append("- [ ] å°è¯•ä¸åŒçš„ç‰¹å¾é›†ç»„åˆæ¶ˆèå®éªŒ")
        lines.append("- [ ] è°ƒä¼˜ learning_rate + n_estimators ç»„åˆ")
        lines.append("- [ ] å¢åŠ æ›´å¤š Walk-Forward folds ä»¥æé«˜è¯„ä¼°ç¨³å®šæ€§")
        lines.append("- [ ] åˆ†æ cohen_kappa åä½çš„åŸå› ï¼ˆæ ‡ç­¾åˆ†å¸ƒï¼Ÿç±»åˆ«ä¸å¹³è¡¡ï¼Ÿï¼‰")
        lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # é™„å½•ï¼šå®éªŒäº§ç‰©æ¸…å•
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("---")
    lines.append("## é™„å½•: å®éªŒäº§ç‰©æ¸…å•")
    lines.append("")

    for exp in experiments:
        exp_dir = exp["dir"]
        lines.append(f"### {exp['short_id']}")
        lines.append(f"- **ç›®å½•**: `{exp_dir}`")
        if exp_dir.exists():
            files = sorted(exp_dir.iterdir())
            for f in files:
                size = f.stat().st_size
                size_str = f"{size / 1024:.1f}KB" if size > 1024 else f"{size}B"
                lines.append(f"  - `{f.name}` ({size_str})")
        lines.append("")

    # â”€â”€ ä¿å­˜ â”€â”€
    report = "\n".join(lines)

    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(report, encoding="utf-8")
        logger.info(f"å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

    return report
